{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F2p6BLc9ygR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e98b9b6-694d-49bc-8b66-24bc9edd3808"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict\n",
        "\n",
        "# NLP library imports\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "_############################################################_\n",
        "# Callback function called on update config\n",
        "_############################################################_\n",
        "def config(configuration: Dict):\n",
        "    # No configuration needed for this example\n",
        "    pass\n",
        "\n",
        "_############################################################_\n",
        "# Callback function called on each execution pass\n",
        "_############################################################_\n",
        "def execute(request, ray, state):\n",
        "    output = []\n",
        "\n",
        "    for text in request:\n",
        "        # Tokenize the input text\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "\n",
        "        # Part-of-speech tagging\n",
        "        tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "        # Extract nouns and adjectives\n",
        "        nouns = [word for word, pos in tagged if pos.startswith('N')]\n",
        "        adjectives = [word for word, pos in tagged if pos.startswith('J')]\n",
        "\n",
        "        # Find synonyms and definitions for nouns and adjectives\n",
        "        response = \"Here are the synonyms and definitions for the nouns and adjectives in your text:\\n\\n\"\n",
        "        for noun in nouns:\n",
        "            synsets = wordnet.synsets(noun)\n",
        "            if synsets:\n",
        "                response += f\"Noun: {noun}\\n\"\n",
        "                response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != noun])}\\n\"\n",
        "                response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "        for adj in adjectives:\n",
        "            synsets = wordnet.synsets(adj)\n",
        "            if synsets:\n",
        "                response += f\"Adjective: {adj}\\n\"\n",
        "                response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != adj])}\\n\"\n",
        "                response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "        output.append(response)\n",
        "\n",
        "    return output"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "from typing import Dict\n",
        "\n",
        "# NLP library imports\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "# Download required NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Callback function called on update config\n",
        "def config(configuration: Dict):\n",
        "    # No configuration needed for this example\n",
        "    pass\n",
        "\n",
        "# Callback function called on each execution pass\n",
        "def execute(request, ray, state):\n",
        "    output = []\n",
        "\n",
        "    for text in request:\n",
        "        # Tokenize the input text\n",
        "        tokens = nltk.word_tokenize(text)\n",
        "\n",
        "        # Part-of-speech tagging\n",
        "        tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "        # Extract nouns and adjectives\n",
        "        nouns = [word for word, pos in tagged if pos.startswith('N')]\n",
        "        adjectives = [word for word, pos in tagged if pos.startswith('J')]\n",
        "\n",
        "        # Find synonyms and definitions for nouns and adjectives\n",
        "        response = \"Here are the synonyms and definitions for the nouns and adjectives in your text:\\n\\n\"\n",
        "        for noun in nouns:\n",
        "            synsets = wordnet.synsets(noun)\n",
        "            if synsets:\n",
        "                response += f\"Noun: {noun}\\n\"\n",
        "                response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != noun])}\\n\"\n",
        "                response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "        for adj in adjectives:\n",
        "            synsets = wordnet.synsets(adj)\n",
        "            if synsets:\n",
        "                response += f\"Adjective: {adj}\\n\"\n",
        "                response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != adj])}\\n\"\n",
        "                response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "        output.append(response)\n",
        "\n",
        "    return output\n",
        "\n",
        "# Run the execute function\n",
        "request = [\"hello  \"]\n",
        "ray = 1  # Replace with appropriate value\n",
        "state = 1  # Replace with appropriate value\n",
        "output = execute(request, ray, state)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJUC60WdEovy",
        "outputId": "409b1a89-9e6d-46f1-c695-2a532f32adf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Here are the synonyms and definitions for the nouns and adjectives in your text:\\n\\nNoun: hello\\nSynonyms: hullo, hi, howdy, how-do-you-do\\nDefinition: an expression of greeting\\n\\n']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load the English language model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the text preprocessing and analysis function\n",
        "def preprocess_and_analyze_text(text):\n",
        "    # Tokenize the input text\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Extract nouns and adjectives\n",
        "    nouns = [token.text for token in doc if token.pos_ == 'NOUN']\n",
        "    adjectives = [token.text for token in doc if token.pos_ == 'ADJ']\n",
        "\n",
        "    # Find synonyms and definitions for nouns and adjectives\n",
        "    response = \"Here are the synonyms and definitions for the nouns and adjectives in your text:\\n\\n\"\n",
        "    for noun in nouns:\n",
        "        synsets = wordnet.synsets(noun)\n",
        "        if synsets:\n",
        "            response += f\"Noun: {noun}\\n\"\n",
        "            response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != noun])}\\n\"\n",
        "            response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "    for adj in adjectives:\n",
        "        synsets = wordnet.synsets(adj)\n",
        "        if synsets:\n",
        "            response += f\"Adjective: {adj}\\n\"\n",
        "            response += f\"Synonyms: {', '.join([syn for syn in synsets[0].lemma_names() if syn != adj])}\\n\"\n",
        "            response += f\"Definition: {synsets[0].definition()}\\n\\n\"\n",
        "\n",
        "    return response\n",
        "\n",
        "# Example usage\n",
        "input_text = \"hello is a great way to start \"\n",
        "output = preprocess_and_analyze_text(input_text)\n",
        "print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYsTc-NnFFcP",
        "outputId": "cb1bcab8-8ab0-4823-adec-cd2bc188ed1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here are the synonyms and definitions for the nouns and adjectives in your text:\n",
            "\n",
            "Noun: way\n",
            "Synonyms: manner, mode, style, fashion\n",
            "Definition: how something is done or how it happens\n",
            "\n",
            "Adjective: great\n",
            "Synonyms: \n",
            "Definition: a person who has achieved distinction and honor in some field\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}